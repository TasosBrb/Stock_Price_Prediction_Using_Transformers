Financial forecasting has long been an important area of research in finance, with the goal of
providing decision-makers with accurate predictions of future financial trends. Recent
advances in Machine Learning and Artificial Intelligence have led to the development of new
techniques that are capable of improving the accuracy of financial forecasting. In this thesis,
we explore the use of Transformer methods for financial forecasting.

The Transformer is a type of neural network architecture that was introduced in 2017 and has
since become a powerful tool for natural language processing tasks. Transformer methods are
known for their ability to effectively capture long-term dependencies, which is critical for
financial forecasting. **In this thesis, we investigate the use of Transformer methods for
financial time series forecasting, and compare their performance to traditional forecasting
methods such as LSTM. Furthermore, we make some tests with diferent possitional enconding.**

As the use of machine learning in finance continues to grow, the findings of this research have
significant implications for decision-makers in the financial industry who rely on accurate
predictions to inform their investment strategies. Future research could explore the
application of Transformer methods in other financial forecasting tasks and investigate the
use of other advanced deep learning techniques to further improve the accuracy of financial
forecasting.
